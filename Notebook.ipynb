{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data(name='ukiyoe2photo'):\n",
    "    # load data from TensorFlow\n",
    "    dataset, metadata = tfds.load('cycle_gan/' + name, with_info=True, as_supervised=True)\n",
    "    train_a, train_b = dataset['trainA'], dataset['trainB']\n",
    "    test_a, test_b = dataset['testA'], dataset['testB']\n",
    "    return train_a, train_b, test_a, test_b\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input,moldename):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.imshow(predictions[0])\n",
    "    plt.axis('off')\n",
    "    plt.savefig('./output/image_at_epoch_{:04d}_{}.png'.format(epoch,moldename))\n",
    "    plt.show()\n",
    "\n",
    "def generate_images(model, test_input):\n",
    "    prediction = model(test_input)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def normalize(image):\n",
    "    # normalizing the images to [-1, 1]\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image,label):\n",
    "    image = normalize(image)\n",
    "    return image\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Orginal implementation from keras_contrib/layer/normalization\n",
    "# =============================================================================\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable(package='Custom',name=None)\n",
    "class GroupNormalization(tf.keras.layers.Layer):\n",
    "    \"\"\"Group normalization layer.\n",
    "    Group Normalization divides the channels into groups and computes\n",
    "    within each group the mean and variance for normalization.\n",
    "    Empirically, its accuracy is more stable than batch norm in a wide\n",
    "    range of small batch sizes, if learning rate is adjusted linearly\n",
    "    with batch sizes.\n",
    "    Relation to Layer Normalization:\n",
    "    If the number of groups is set to 1, then this operation becomes identical\n",
    "    to Layer Normalization.\n",
    "    Relation to Instance Normalization:\n",
    "    If the number of groups is set to the\n",
    "    input dimension (number of groups is equal\n",
    "    to number of channels), then this operation becomes\n",
    "    identical to Instance Normalization.\n",
    "    Arguments\n",
    "        groups: Integer, the number of groups for Group Normalization.\n",
    "            Can be in the range [1, N] where N is the input dimension.\n",
    "            The input dimension must be divisible by the number of groups.\n",
    "        axis: Integer, the axis that should be normalized.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    Output shape\n",
    "        Same shape as input.\n",
    "    References\n",
    "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 groups=2,\n",
    "                 axis=-1,\n",
    "                 epsilon=1e-3,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.groups = groups\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = tf.keras.initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = tf.keras.initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = tf.keras.regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = tf.keras.regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = tf.keras.constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = tf.keras.constraints.get(gamma_constraint)\n",
    "        self._check_axis()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self._check_if_input_shape_is_none(input_shape)\n",
    "        self._set_number_of_groups_for_instance_norm(input_shape)\n",
    "        self._check_size_of_dimensions(input_shape)\n",
    "        self._create_input_spec(input_shape)\n",
    "\n",
    "        self._add_gamma_weight(input_shape)\n",
    "        self._add_beta_weight(input_shape)\n",
    "        self.built = True\n",
    "        super(GroupNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        input_shape = tf.keras.backend.int_shape(inputs)\n",
    "        tensor_input_shape = tf.shape(inputs)\n",
    "\n",
    "        reshaped_inputs, group_shape = self._reshape_into_groups(\n",
    "            inputs, input_shape, tensor_input_shape)\n",
    "\n",
    "        normalized_inputs = self._apply_normalization(reshaped_inputs,\n",
    "                                                      input_shape)\n",
    "\n",
    "        outputs = tf.reshape(normalized_inputs, tensor_input_shape)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'groups':\n",
    "            self.groups,\n",
    "            'axis':\n",
    "            self.axis,\n",
    "            'epsilon':\n",
    "            self.epsilon,\n",
    "            'center':\n",
    "            self.center,\n",
    "            'scale':\n",
    "            self.scale,\n",
    "            'beta_initializer':\n",
    "            tf.keras.initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer':\n",
    "            tf.keras.initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer':\n",
    "            tf.keras.regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer':\n",
    "            tf.keras.regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint':\n",
    "            tf.keras.constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint':\n",
    "            tf.keras.constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(GroupNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def _reshape_into_groups(self, inputs, input_shape, tensor_input_shape):\n",
    "\n",
    "        group_shape = [tensor_input_shape[i] for i in range(len(input_shape))]\n",
    "        group_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        group_shape.insert(self.axis, self.groups)\n",
    "        group_shape = tf.stack(group_shape)\n",
    "        reshaped_inputs = tf.reshape(inputs, group_shape)\n",
    "        return reshaped_inputs, group_shape\n",
    "\n",
    "    def _apply_normalization(self, reshaped_inputs, input_shape):\n",
    "\n",
    "        group_shape = tf.keras.backend.int_shape(reshaped_inputs)\n",
    "        group_reduction_axes = list(range(1, len(group_shape)))\n",
    "        axis = -2 if self.axis == -1 else self.axis - 1\n",
    "        group_reduction_axes.pop(axis)\n",
    "\n",
    "        mean, variance = tf.nn.moments(\n",
    "            reshaped_inputs, group_reduction_axes, keepdims=True)\n",
    "\n",
    "        gamma, beta = self._get_reshaped_weights(input_shape)\n",
    "        normalized_inputs = tf.nn.batch_normalization(\n",
    "            reshaped_inputs,\n",
    "            mean=mean,\n",
    "            variance=variance,\n",
    "            scale=gamma,\n",
    "            offset=beta,\n",
    "            variance_epsilon=self.epsilon)\n",
    "        return normalized_inputs\n",
    "\n",
    "    def _get_reshaped_weights(self, input_shape):\n",
    "        broadcast_shape = self._create_broadcast_shape(input_shape)\n",
    "        gamma = None\n",
    "        beta = None\n",
    "        if self.scale:\n",
    "            gamma = tf.reshape(self.gamma, broadcast_shape)\n",
    "\n",
    "        if self.center:\n",
    "            beta = tf.reshape(self.beta, broadcast_shape)\n",
    "        return gamma, beta\n",
    "\n",
    "    def _check_if_input_shape_is_none(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "\n",
    "    def _set_number_of_groups_for_instance_norm(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "\n",
    "        if self.groups == -1:\n",
    "            self.groups = dim\n",
    "\n",
    "    def _check_size_of_dimensions(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        if dim < self.groups:\n",
    "            raise ValueError(\n",
    "                'Number of groups (' + str(self.groups) + ') cannot be '\n",
    "                'more than the number of channels (' + str(dim) + ').')\n",
    "\n",
    "        if dim % self.groups != 0:\n",
    "            raise ValueError(\n",
    "                'Number of groups (' + str(self.groups) + ') must be a '\n",
    "                'multiple of the number of channels (' + str(dim) + ').')\n",
    "\n",
    "    def _check_axis(self):\n",
    "\n",
    "        if self.axis == 0:\n",
    "            raise ValueError(\n",
    "                \"You are trying to normalize your batch axis. Do you want to \"\n",
    "                \"use tf.layer.batch_normalization instead\")\n",
    "\n",
    "    def _create_input_spec(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        self.input_spec = tf.keras.layers.InputSpec(\n",
    "            ndim=len(input_shape), axes={self.axis: dim})\n",
    "\n",
    "    def _add_gamma_weight(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(\n",
    "                shape=shape,\n",
    "                name='gamma',\n",
    "                initializer=self.gamma_initializer,\n",
    "                regularizer=self.gamma_regularizer,\n",
    "                constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "\n",
    "    def _add_beta_weight(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(\n",
    "                shape=shape,\n",
    "                name='beta',\n",
    "                initializer=self.beta_initializer,\n",
    "                regularizer=self.beta_regularizer,\n",
    "                constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "\n",
    "    def _create_broadcast_shape(self, input_shape):\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        broadcast_shape.insert(self.axis, self.groups)\n",
    "        return broadcast_shape\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable(package='Addons')\n",
    "class InstanceNormalization(GroupNormalization):\n",
    "    \"\"\"Instance normalization layer.\n",
    "    Instance Normalization is an specific case of ```GroupNormalization```since\n",
    "    it normalizes all features of one channel. The Groupsize is equal to the\n",
    "    channel size. Empirically, its accuracy is more stable than batch norm in a\n",
    "    wide range of small batch sizes, if learning rate is adjusted linearly\n",
    "    with batch sizes.\n",
    "    Arguments\n",
    "        axis: Integer, the axis that should be normalized.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    Output shape\n",
    "        Same shape as input.\n",
    "    References\n",
    "        - [Instance Normalization: The Missing Ingredient for Fast Stylization]\n",
    "        (https://arxiv.org/abs/1607.08022)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        if \"groups\" in kwargs:\n",
    "            logging.warning(\"The given value for groups will be overwritten.\")\n",
    "\n",
    "        kwargs[\"groups\"] = -1\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normes(norm):\n",
    "    if norm == 'none':\n",
    "        return lambda: lambda x: x\n",
    "    elif norm == 'batch_norm':\n",
    "        return kl.BatchNormalization\n",
    "    elif norm == 'instance_norm':\n",
    "        return InstanceNormalization\n",
    "    elif norm == 'layer_norm':\n",
    "        return kl.LayerNormalization\n",
    "\n",
    "# Define Generator architecture\n",
    "def generator(input_shape=(256, 256, 3), output_channels=3, dim=64, n_downsamplings=2, n_blocks=9, norm='instance_norm'):\n",
    "    norme = normes(norm)\n",
    "\n",
    "    def resnet_block(x):\n",
    "        dim = x.shape[-1]\n",
    "        h = x\n",
    "\n",
    "        h = tf.pad(h, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n",
    "        h = kl.Conv2D(dim, 3, padding='valid', use_bias=False)(h)\n",
    "        h = norme()(h)\n",
    "        h = tf.nn.relu(h)\n",
    "\n",
    "        h = tf.pad(h, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n",
    "        h = kl.Conv2D(dim, 3, padding='valid', use_bias=False)(h)\n",
    "        h = norme()(h)\n",
    "\n",
    "        return kl.add([x, h])\n",
    "\n",
    "    # 0\n",
    "    h = inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # 1, Convolution 64 filtres\n",
    "    h = tf.pad(h, [[0, 0], [3, 3], [3, 3], [0, 0]], mode='REFLECT')\n",
    "    h = kl.Conv2D(dim, 7, padding='valid', use_bias=False)(h)\n",
    "    h = norme()(h)\n",
    "    h = tf.nn.relu(h)\n",
    "\n",
    "    # 2, Convolution 128, et 256 filtres\n",
    "    for _ in range(n_downsamplings):\n",
    "        dim *= 2\n",
    "        h = kl.Conv2D(dim, 3, strides=2, padding='same', use_bias=False)(h)\n",
    "        h = norme()(h)\n",
    "        h = tf.nn.relu(h)\n",
    "\n",
    "    # 3, Resnet Block (x9)\n",
    "    for _ in range(n_blocks):\n",
    "        h = resnet_block(h)\n",
    "\n",
    "    # 4, Déconvolution 128, 64 filtres\n",
    "    for _ in range(n_downsamplings):\n",
    "        dim //= 2\n",
    "        h = kl.Conv2DTranspose(dim, 3, strides=2, padding='same', use_bias=False)(h)\n",
    "        h = norme()(h)\n",
    "        h = tf.nn.relu(h)\n",
    "\n",
    "    # 5, Convolution 3 filtres\n",
    "    h = tf.pad(h, [[0, 0], [3, 3], [3, 3], [0, 0]], mode='REFLECT')\n",
    "    h = kl.Conv2D(output_channels, 7, padding='valid')(h)\n",
    "    h = tf.tanh(h)\n",
    "\n",
    "    return km.Model(inputs=inputs, outputs=h)\n",
    "\n",
    "def discriminator(input_shape=(256, 256, 3), dim=64, n_downsamplings=3, norm='instance_norm'):\n",
    "    dim_ = dim\n",
    "    norme = normes(norm)\n",
    "\n",
    "    # 0\n",
    "    h = inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # 1\n",
    "    h = kl.Conv2D(dim, 4, strides=2, padding='same')(h)\n",
    "    h = tf.nn.leaky_relu(h, alpha=0.2)\n",
    "\n",
    "    for _ in range(n_downsamplings - 1):\n",
    "        dim = min(dim * 2, dim_ * 8)\n",
    "        h = kl.Conv2D(dim, 4, strides=2, padding='same', use_bias=False)(h)\n",
    "        h = norme()(h)\n",
    "        h = tf.nn.leaky_relu(h, alpha=0.2)\n",
    "\n",
    "    # 2\n",
    "    dim = min(dim * 2, dim_ * 8)\n",
    "    h = kl.Conv2D(dim, 4, strides=1, padding='same', use_bias=False)(h)\n",
    "    h = norme()(h)\n",
    "    h = tf.nn.leaky_relu(h, alpha=0.2)\n",
    "\n",
    "    # 3\n",
    "    h = kl.Conv2D(1, 4, strides=1, padding='same')(h)\n",
    "\n",
    "    return km.Model(inputs=inputs, outputs=h)\n",
    "\n",
    "# Define losses\n",
    "LAMBDA = 10  # Additional Weigh for the cycle loss and identity loss\n",
    "\n",
    "# Generator loss\n",
    "def gen_loss(generated):\n",
    "    # Maximise the likehood of generated photo to be considered real, ie 1\n",
    "    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(generated), generated)\n",
    "\n",
    "# Discriminator Loss\n",
    "def disc_loss(real, generated):\n",
    "    # Maximise the likehood of the real photo, ie 1\n",
    "    # Minimise the likehood of generated photo, ie 0\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real), real)\n",
    "    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss/2\n",
    "\n",
    "# Cycle loss\n",
    "def cycle_loss(real_image, cycled_image):\n",
    "    # difference between original image an cycled image\n",
    "    cycl_loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    return LAMBDA * cycl_loss\n",
    "\n",
    "# Identity loss\n",
    "def identity_loss(real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return 1 * 0.5 * loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_a, real_b, gen_a, gen_b, disc_a, disc_b, gen_a_opt, gen_b_opt, disc_a_opt, disc_b_opt):\n",
    "\n",
    "    # persistent is set to True because the tape is used more than\n",
    "    # once to calculate the gradients.\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generators\n",
    "        fake_b = gen_a(real_a, training=True)\n",
    "        cycled_a = gen_b(fake_b, training=True)\n",
    "        fake_a = gen_b(real_b, training=True)\n",
    "        cycled_b = gen_a(fake_a, training=True)\n",
    "\n",
    "        # same_a and same_b are used for identity loss.\n",
    "        same_a = gen_a(real_a, training=True)\n",
    "        same_b = gen_b(real_b, training=True)\n",
    "\n",
    "        # Discriminator\n",
    "        disc_real_a = disc_a(real_a, training=True)\n",
    "        disc_real_b = disc_b(real_b, training=True)\n",
    "        disc_fake_a = disc_a(fake_a, training=True)\n",
    "        disc_fake_b = disc_b(fake_b, training=True)\n",
    "\n",
    "        # calculate the loss\n",
    "        gen_a_loss = gen_loss(disc_fake_b)\n",
    "        gen_b_loss = gen_loss(disc_fake_a)\n",
    "\n",
    "        total_cycle_loss = cycle_loss(real_a, cycled_a) + cycle_loss(real_b, cycled_b)\n",
    "\n",
    "        # Total generator loss = adversarial loss + cycle loss + identity loss\n",
    "        total_gen_b_loss = gen_b_loss + total_cycle_loss + identity_loss(real_b, same_b)\n",
    "        total_gen_a_loss = gen_a_loss + total_cycle_loss + identity_loss(real_a, same_a)\n",
    "\n",
    "        disc_a_loss = disc_loss(disc_real_a, disc_fake_a)\n",
    "        disc_b_loss = disc_loss(disc_real_b, disc_fake_b)\n",
    "\n",
    "    # Calculate the gradients for generator and discriminator\n",
    "    generator_b_gradients = tape.gradient(total_gen_b_loss, gen_b.trainable_variables)\n",
    "    generator_a_gradients = tape.gradient(total_gen_a_loss, gen_a.trainable_variables)\n",
    "\n",
    "    discriminator_a_gradients = tape.gradient(disc_a_loss, disc_a.trainable_variables)\n",
    "    discriminator_b_gradients = tape.gradient(disc_b_loss, disc_b.trainable_variables)\n",
    "\n",
    "    # Apply the gradients to the optimizer\n",
    "    gen_b_opt.apply_gradients(zip(generator_b_gradients, gen_b.trainable_variables))\n",
    "    gen_a_opt.apply_gradients(zip(generator_a_gradients, gen_a.trainable_variables))\n",
    "    disc_a_opt.apply_gradients(zip(discriminator_a_gradients, disc_a.trainable_variables))\n",
    "    disc_b_opt.apply_gradients(zip(discriminator_b_gradients, disc_b.trainable_variables))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set Global Variables\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "tfds.disable_progress_bar()\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Load data\n",
    "train_a, train_b, test_a, test_b = load_data(name='ukiyoe2photo')\n",
    "\n",
    "# Transform data\n",
    "train_a = train_a.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)\n",
    "train_b = train_b.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)\n",
    "test_a = test_a.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)\n",
    "test_b = test_b.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)\n",
    "\n",
    "# Instanciate Networks\n",
    "gen_a = generator((256, 256, 3))\n",
    "gen_b = generator((256, 256, 3))\n",
    "disc_a = discriminator((256, 256, 3))\n",
    "disc_b = discriminator((256, 256, 3))\n",
    "\n",
    "# Optimiseur\n",
    "generator_a_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_b_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_a_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_b_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save check\n",
    "# Create a checkpoint\n",
    "checkpoint_path = \"./checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=gen_a,\n",
    "                           generator_f=gen_b,\n",
    "                           discriminator_x=disc_a,\n",
    "                           discriminator_y=disc_b,\n",
    "                           generator_g_optimizer=generator_a_optimizer,\n",
    "                           generator_f_optimizer=generator_b_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_a_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_b_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored!!')\n",
    "\n",
    "# Draw a sample\n",
    "sample_a = next(iter(train_a))\n",
    "sample_b = next(iter(train_b))\n",
    "\n",
    "# Train the models\n",
    "seed = tf.random.normal([1, 256, 256, 3])\n",
    "for epoch in range(10):\n",
    "    start = time.time()\n",
    "    n = 0\n",
    "    for image_A, image_B in tf.data.Dataset.zip((train_a, train_b)):\n",
    "        print(\"trainstep\")\n",
    "        train_step(image_A, image_B, gen_a, gen_b, disc_a, disc_b, generator_a_optimizer,\n",
    "                   generator_b_optimizer, discriminator_a_optimizer, discriminator_b_optimizer)\n",
    "        if n % 10 == 0:\n",
    "            print(n / 10, end=' ')\n",
    "        n += 1\n",
    "\n",
    "    # Using a consistent image (sample_horse) so that the progress of the model\n",
    "    # is clearly visible.\n",
    "    generate_and_save_images(gen_a, epoch + 1, sample_a, 'A')\n",
    "    generate_and_save_images(gen_b, epoch + 1, sample_b, 'B')\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print('Saving checkpoint for epoch {} at {}'.format(epoch + 1,\n",
    "                                                            ckpt_save_path))\n",
    "\n",
    "    print('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                       time.time() - start))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
