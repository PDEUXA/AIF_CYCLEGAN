{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow_addons as tfa\n",
    "import time\n",
    "\n",
    "def load_data(name='ukiyoe2photo'):\n",
    "    # load data from TensorFlow\n",
    "    dataset, metadata = tfds.load('cycle_gan/' + name, with_info=True, as_supervised=True)\n",
    "    train_a, train_b = dataset['trainA'], dataset['trainB']\n",
    "    test_a, test_b = dataset['testA'], dataset['testB']\n",
    "    return train_a, train_b, test_a, test_b\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input,moldename):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.imshow(predictions[0])\n",
    "    plt.axis('off')\n",
    "    plt.savefig('image_at_epoch_{:04d}_{}.png'.format(epoch,moldename))\n",
    "    plt.show()\n",
    "\n",
    "def generate_images(model, test_input):\n",
    "    prediction = model(test_input)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def normalize(image):\n",
    "    # normalizing the images to [-1, 1]\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image,label):\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "def normes(norm):\n",
    "    if norm == 'none':\n",
    "        return lambda: lambda x: x\n",
    "    elif norm == 'batch_norm':\n",
    "        return kl.BatchNormalization\n",
    "    elif norm == 'instance_norm':\n",
    "        return tfa.layers.InstanceNormalization\n",
    "    elif norm == 'layer_norm':\n",
    "        return kl.LayerNormalization\n",
    "\n",
    "# Define Generator architecture\n",
    "def generator(input_shape=(256, 256, 3), output_channels=3, dim=64, n_downsamplings=2, n_blocks=9, norm='instance_norm'):\n",
    "    norme = normes(norm)\n",
    "\n",
    "    def resnet_block(x):\n",
    "        dim = x.shape[-1]\n",
    "        h = x\n",
    "\n",
    "        h = tf.pad(h, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n",
    "        h = kl.Conv2D(dim, 3, padding='valid', use_bias=False)(h)\n",
    "        h = norme()(h)\n",
    "        h = tf.nn.relu(h)\n",
    "\n",
    "        h = tf.pad(h, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n",
    "        h = kl.Conv2D(dim, 3, padding='valid', use_bias=False)(h)\n",
    "        h = norme()(h)\n",
    "\n",
    "        return kl.add([x, h])\n",
    "\n",
    "    # 0\n",
    "    h = inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # 1, Convolution 64 filtres\n",
    "    h = tf.pad(h, [[0, 0], [3, 3], [3, 3], [0, 0]], mode='REFLECT')\n",
    "    h = kl.Conv2D(dim, 7, padding='valid', use_bias=False)(h)\n",
    "    h = norme()(h)\n",
    "    h = tf.nn.relu(h)\n",
    "\n",
    "    # 2, Convolution 128, et 256 filtres\n",
    "    for _ in range(n_downsamplings):\n",
    "        dim *= 2\n",
    "        h = kl.Conv2D(dim, 3, strides=2, padding='same', use_bias=False)(h)\n",
    "        h = norme()(h)\n",
    "        h = tf.nn.relu(h)\n",
    "\n",
    "    # 3, Resnet Block (x9)\n",
    "    for _ in range(n_blocks):\n",
    "        h = resnet_block(h)\n",
    "\n",
    "    # 4, DÃ©convolution 128, 64 filtres\n",
    "    for _ in range(n_downsamplings):\n",
    "        dim //= 2\n",
    "        h = kl.Conv2DTranspose(dim, 3, strides=2, padding='same', use_bias=False)(h)\n",
    "        h = norme()(h)\n",
    "        h = tf.nn.relu(h)\n",
    "\n",
    "    # 5, Convolution 3 filtres\n",
    "    h = tf.pad(h, [[0, 0], [3, 3], [3, 3], [0, 0]], mode='REFLECT')\n",
    "    h = kl.Conv2D(output_channels, 7, padding='valid')(h)\n",
    "    h = tf.tanh(h)\n",
    "\n",
    "    return km.Model(inputs=inputs, outputs=h)\n",
    "\n",
    "def discriminator(input_shape=(256, 256, 3), dim=64, n_downsamplings=3, norm='instance_norm'):\n",
    "    dim_ = dim\n",
    "    norme = normes(norm)\n",
    "\n",
    "    # 0\n",
    "    h = inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # 1\n",
    "    h = kl.Conv2D(dim, 4, strides=2, padding='same')(h)\n",
    "    h = tf.nn.leaky_relu(h, alpha=0.2)\n",
    "\n",
    "    for _ in range(n_downsamplings - 1):\n",
    "        dim = min(dim * 2, dim_ * 8)\n",
    "        h = kl.Conv2D(dim, 4, strides=2, padding='same', use_bias=False)(h)\n",
    "        h = norme()(h)\n",
    "        h = tf.nn.leaky_relu(h, alpha=0.2)\n",
    "\n",
    "    # 2\n",
    "    dim = min(dim * 2, dim_ * 8)\n",
    "    h = kl.Conv2D(dim, 4, strides=1, padding='same', use_bias=False)(h)\n",
    "    h = norme()(h)\n",
    "    h = tf.nn.leaky_relu(h, alpha=0.2)\n",
    "\n",
    "    # 3\n",
    "    h = kl.Conv2D(1, 4, strides=1, padding='same')(h)\n",
    "\n",
    "    return km.Model(inputs=inputs, outputs=h)\n",
    "\n",
    "# Define losses\n",
    "LAMBDA = 10  # Additional Weigh for the cycle loss and identity loss\n",
    "\n",
    "# Generator loss\n",
    "def gen_loss(generated):\n",
    "    # Maximise the likehood of generated photo to be considered real, ie 1\n",
    "    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(generated), generated)\n",
    "\n",
    "# Discriminator Loss\n",
    "def disc_loss(real, generated):\n",
    "    # Maximise the likehood of the real photo, ie 1\n",
    "    # Minimise the likehood of generated photo, ie 0\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real), real)\n",
    "    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss/2\n",
    "\n",
    "# Cycle loss\n",
    "def cycle_loss(real_image, cycled_image):\n",
    "    # difference between original image an cycled image\n",
    "    cycl_loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    return LAMBDA * cycl_loss\n",
    "\n",
    "# Identity loss\n",
    "def identity_loss(real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return 1 * 0.5 * loss\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_a, real_b, gen_a, gen_b, disc_a, disc_b, gen_a_opt, gen_b_opt, disc_a_opt, disc_b_opt):\n",
    "\n",
    "    # persistent is set to True because the tape is used more than\n",
    "    # once to calculate the gradients.\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generators\n",
    "        fake_b = gen_a(real_a, training=True)\n",
    "        cycled_a = gen_b(fake_b, training=True)\n",
    "        fake_a = gen_b(real_b, training=True)\n",
    "        cycled_b = gen_a(fake_a, training=True)\n",
    "\n",
    "        # same_a and same_b are used for identity loss.\n",
    "        same_a = gen_a(real_a, training=True)\n",
    "        same_b = gen_b(real_b, training=True)\n",
    "\n",
    "        # Discriminator\n",
    "        disc_real_a = disc_a(real_a, training=True)\n",
    "        disc_real_b = disc_b(real_b, training=True)\n",
    "        disc_fake_a = disc_a(fake_a, training=True)\n",
    "        disc_fake_b = disc_b(fake_b, training=True)\n",
    "\n",
    "        # calculate the loss\n",
    "        gen_a_loss = gen_loss(disc_fake_b)\n",
    "        gen_b_loss = gen_loss(disc_fake_a)\n",
    "\n",
    "        total_cycle_loss = cycle_loss(real_a, cycled_a) + cycle_loss(real_b, cycled_b)\n",
    "\n",
    "        # Total generator loss = adversarial loss + cycle loss + identity loss\n",
    "        total_gen_b_loss = gen_b_loss + total_cycle_loss + identity_loss(real_b, same_b)\n",
    "        total_gen_a_loss = gen_a_loss + total_cycle_loss + identity_loss(real_a, same_a)\n",
    "\n",
    "        disc_a_loss = disc_loss(disc_real_a, disc_fake_a)\n",
    "        disc_b_loss = disc_loss(disc_real_b, disc_fake_b)\n",
    "\n",
    "    # Calculate the gradients for generator and discriminator\n",
    "    generator_b_gradients = tape.gradient(total_gen_b_loss, gen_b.trainable_variables)\n",
    "    generator_a_gradients = tape.gradient(total_gen_a_loss, gen_a.trainable_variables)\n",
    "\n",
    "    discriminator_a_gradients = tape.gradient(disc_a_loss, disc_a.trainable_variables)\n",
    "    discriminator_b_gradients = tape.gradient(disc_b_loss, disc_b.trainable_variables)\n",
    "\n",
    "    # Apply the gradients to the optimizer\n",
    "    gen_b_opt.apply_gradients(zip(generator_b_gradients, gen_b.trainable_variables))\n",
    "    gen_a_opt.apply_gradients(zip(generator_a_gradients, gen_a.trainable_variables))\n",
    "    disc_a_opt.apply_gradients(zip(discriminator_a_gradients, disc_a.trainable_variables))\n",
    "    disc_b_opt.apply_gradients(zip(discriminator_b_gradients, disc_b.trainable_variables))\n",
    "\n",
    "# Set Global Variables\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "tfds.disable_progress_bar()\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Load data\n",
    "train_a, train_b, test_a, test_b = load_data(name='ukiyoe2photo')\n",
    "\n",
    "# Transform data\n",
    "train_a = train_a.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)\n",
    "train_b = train_b.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)\n",
    "test_a = test_a.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)\n",
    "test_b = test_b.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)\n",
    "\n",
    "# Instanciate Networks\n",
    "gen_a = generator((256, 256, 3))\n",
    "gen_b = generator((256, 256, 3))\n",
    "disc_a = discriminator((256, 256, 3))\n",
    "disc_b = discriminator((256, 256, 3))\n",
    "\n",
    "# Optimiseur\n",
    "generator_a_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_b_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_a_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_b_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "# Save check\n",
    "# Create a checkpoint\n",
    "checkpoint_path = \"./checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=gen_a,\n",
    "                           generator_f=gen_b,\n",
    "                           discriminator_x=disc_a,\n",
    "                           discriminator_y=disc_b,\n",
    "                           generator_g_optimizer=generator_a_optimizer,\n",
    "                           generator_f_optimizer=generator_b_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_a_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_b_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored!!')\n",
    "\n",
    "# Draw a sample\n",
    "sample_a = next(iter(train_a))\n",
    "sample_b = next(iter(train_b))\n",
    "\n",
    "# Train the models\n",
    "seed = tf.random.normal([1, 256, 256, 3])\n",
    "for epoch in range(10):\n",
    "    start = time.time()\n",
    "    n = 0\n",
    "    for image_A, image_B in tf.data.Dataset.zip((train_a, train_b)):\n",
    "        print(\"trainstep\")\n",
    "        train_step(image_A, image_B, gen_a, gen_b, disc_a, disc_b, generator_a_optimizer,\n",
    "                   generator_b_optimizer, discriminator_a_optimizer, discriminator_b_optimizer)\n",
    "        if n % 10 == 0:\n",
    "            print(n / 10, end=' ')\n",
    "        n += 1\n",
    "\n",
    "    # Using a consistent image (sample_horse) so that the progress of the model\n",
    "    # is clearly visible.\n",
    "    generate_and_save_images(gen_a, epoch + 1, sample_a, 'A')\n",
    "    generate_and_save_images(gen_b, epoch + 1, sample_b, 'B')\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print('Saving checkpoint for epoch {} at {}'.format(epoch + 1,\n",
    "                                                            ckpt_save_path))\n",
    "\n",
    "    print('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                       time.time() - start))\n",
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
